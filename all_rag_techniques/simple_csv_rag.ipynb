{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Simple RAG (Retrieval-Augmented Generation) System for CSV Files\n",
    "\n",
    "## Overview\n",
    "\n",
    "This code implements a basic Retrieval-Augmented Generation (RAG) system for processing and querying CSV documents. The system encodes the document content into a vector store, which can then be queried to retrieve relevant information.\n",
    "\n",
    "# CSV File Structure and Use Case\n",
    "The CSV file contains dummy customer data, comprising various attributes like first name, last name, company, etc. This dataset will be utilized for a RAG use case, facilitating the creation of a customer information Q&A system.\n",
    "\n",
    "## Key Components\n",
    "\n",
    "1. Loading and spliting csv files.\n",
    "2. Vector store creation using [FAISS](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/) and OpenAI embeddings\n",
    "3. Retriever setup for querying the processed documents\n",
    "4. Creating a question and answer over the csv data.\n",
    "\n",
    "## Method Details\n",
    "\n",
    "### Document Preprocessing\n",
    "\n",
    "1. The csv is loaded using langchain Csvloader\n",
    "2. The data is split into chunks.\n",
    "\n",
    "\n",
    "### Vector Store Creation\n",
    "\n",
    "1. OpenAI embeddings are used to create vector representations of the text chunks.\n",
    "2. A FAISS vector store is created from these embeddings for efficient similarity search.\n",
    "\n",
    "### Retriever Setup\n",
    "\n",
    "1. A retriever is configured to fetch the most relevant chunks for a given query.\n",
    "\n",
    "## Benefits of this Approach\n",
    "\n",
    "1. Scalability: Can handle large documents by processing them in chunks.\n",
    "2. Flexibility: Easy to adjust parameters like chunk size and number of retrieved results.\n",
    "3. Efficiency: Utilizes FAISS for fast similarity search in high-dimensional spaces.\n",
    "4. Integration with Advanced NLP: Uses OpenAI embeddings for state-of-the-art text representation.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This simple RAG system provides a solid foundation for building more complex information retrieval and question-answering systems. By encoding document content into a searchable vector store, it enables efficient retrieval of relevant information in response to queries. This approach is particularly useful for applications requiring quick access to specific information within a csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option one - Meta Llama 3 8B - on cpu - SUPER SLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Option one - Meta Llama 3 8B - on cpu - SUPER SLOW\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "# from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "llm = GPT4All(model=\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Option 2 - Hugging Face pipeline - faster with GPU"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#  Option two - Ollama - faster with GPU\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "model_id = \"llama3.1\"\n",
    "llm = ChatOllama(model=model_id, temperature=0)\n",
    "embeddings = OllamaEmbeddings(model=model_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-14T14:32:36.766136802Z",
     "start_time": "2024-09-14T14:32:35.878124009Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the beginning of our conversation, so I don't have any prior memory or context. I'm happy to chat with you now, though! What would you like to talk about?\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"do you remember what I said?\")\n",
    "print(response.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-14T14:35:08.188861867Z",
     "start_time": "2024-09-14T14:35:07.538742316Z"
    }
   },
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV File Structure and Use Case\n",
    "The CSV file contains dummy customer data, comprising various attributes like first name, last name, company, etc. This dataset will be utilized for a RAG use case, facilitating the creation of a customer information Q&A system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-14T08:10:45.613264640Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '../data/customers-100.csv' # insert the path of the csv file\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "#preview the csv file\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load and process csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:27:32.671786052Z",
     "start_time": "2024-09-14T07:27:32.669009396Z"
    }
   },
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path=file_path)\n",
    "docs = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate faiss vector store and openai embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:27:35.321138426Z",
     "start_time": "2024-09-14T07:27:33.695838610Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dor/PycharmProjects/RAG_Techniques/rag_env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "index = faiss.IndexFlatL2(len(embeddings.embed_query(\" \")))\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the splitted csv data to the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:27:36.462680683Z",
     "start_time": "2024-09-14T07:27:36.398960091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['7282ee4c-f4b4-4e02-b4b4-608320d4a0ff',\n 'f5794194-468e-4fc5-893a-52a6fa031bdd',\n '4fe947d6-f5e2-4c19-adeb-4eb54728b7ff',\n '9e88dcf5-8773-43ef-b17b-6b4c39399be6',\n '0b0eb398-4e2b-4ded-a648-b998c18fa08c',\n '18ea91c0-70b6-47d5-99ec-2f34063b1930',\n '50f07c63-ce96-44c7-879f-d7c216e5ee00',\n '46607f4f-fb44-4820-ae3c-68e81ef82031',\n '2520167f-6c0e-4b78-8568-97c5f083a6d8',\n 'fc47cab5-7f72-4802-a99b-6d1fb374a87d',\n '3e90c62e-7c03-4c07-a64c-dc97137414b5',\n '3c21258d-174b-4f88-8d35-2c614d65ec03',\n '9de4923f-0be1-48f7-9805-fc8f430ef0ec',\n '2551567e-c2bc-4480-ad53-1a847b6b92ef',\n '186af085-5648-4140-a253-41141ffd87cf',\n '8c8d5c72-6600-42b6-a332-5b3aee2dd2ff',\n 'b2cc1719-3b58-4826-8331-3e89a0e3480c',\n 'd0c39537-2feb-45f9-94f4-8ec546de6bdc',\n '32a5b976-e2ef-4304-ab6a-23b2bcbe70a1',\n 'fd4b495b-9c80-4ab4-9da5-d9a3dc7ae3b4',\n '318c65ec-bc0d-455d-a5f7-4d0d6397f714',\n '86e980ca-2644-485f-a2dc-f0b0658b41e4',\n 'efd0c379-5c9d-44c8-9d2a-ee885ba8f5ed',\n '92793092-7996-4260-bed0-ee0ce6ae059c',\n '631407a6-22b7-490f-8704-487e60e47879',\n '6d57bd50-e335-435c-b8b0-2fcc89a0019f',\n '39154d12-aabf-4813-b944-18701a97e9fe',\n '89b1db58-f228-4826-a78e-65f2d2a548ee',\n '1894cbc4-79e9-463b-9e41-408d4b0e2844',\n '89e02258-7d78-43ab-9c01-d022ff8ebb89',\n '54f9596f-8e8e-4f00-8734-f1a95627b237',\n '7c9a1a23-30c7-4096-856f-c04e65c250f3',\n 'a289e781-23e7-4fd9-a684-a3783aa58840',\n '1ff0838f-6a2e-4df7-97b7-2bd4945a66da',\n '374e7119-3082-403f-a425-230ec47eeaf2',\n 'af7e5e75-9402-491c-8bc6-d908459690b1',\n 'e19f2a8c-2e36-429a-be90-5e60af86fc63',\n 'ad98162b-8b38-413a-8d8a-fa5c99f43c3f',\n '3142ada4-10cd-4f59-8a01-9a854157bf5b',\n 'e875ed56-c134-4f38-9a0c-807287acbe45',\n '35af28ff-8c5c-40aa-9afa-ca14d0d01c79',\n '5a4a6c3a-10b0-4ec3-b011-d44148a58ec5',\n 'cb23a130-f44a-4c06-ad6c-671bfd303bab',\n 'd38deb15-12b2-4ffb-a5db-2f21a5ac99c4',\n '46c3949e-f2c7-4163-883c-c0676ed82dca',\n '4aeb19bc-c22c-4e1d-86fb-c8ca6e30c2aa',\n 'a714eaf3-bfae-408f-8bae-0f8a95ade614',\n 'fa9989ba-d3d7-43ba-b49e-40cc6a27cb19',\n '49fee2ee-d22e-4cf6-b505-fd3b28b35064',\n '3aa5f471-4291-48f7-886f-2eb668fa4f07',\n 'b7cc45e4-992f-4945-9586-4a625c46ed19',\n 'e6dcde9e-3c9d-44c9-9e83-fb9932110e24',\n '33ea273f-ffef-4be6-ada4-592a8609c5dc',\n '88c29079-5114-4727-8ffb-f6fe7791cfcd',\n '7732a265-ad96-45a4-91f0-bf159fca7385',\n 'a63d30a6-0230-474e-a011-28d7db477057',\n '481b2b23-01da-47b7-8755-fbe6895e65ed',\n 'd679a467-3556-43d9-8be3-9ccef8c85bd2',\n 'ce5610d1-bc79-4bd9-9c1c-f361c7cd5822',\n 'dc4f9ae7-ba21-4c80-957c-f925ba36c25f',\n 'bc961fe8-df80-4b75-a2ef-2d8ed5d4654e',\n '1a88adbd-aad9-4283-a1d4-eacfea27b59f',\n '81e9360e-7641-4a12-88d1-2083ecabec8a',\n '40cd690c-962e-495c-bd75-b8119618d685',\n '313ce660-1d26-4183-9c3b-a259c61731d1',\n '22484954-6e97-4b5f-8bee-9d683048401a',\n '4274dab9-c4da-4dfe-b4ae-a94ecc0bc9d4',\n 'd076342d-ca07-4e17-b3ae-332ca3427be2',\n '5f882779-d637-4180-8cbb-0cc63150a65c',\n 'dd7362fa-e6e4-4fe4-baf0-d379ae33367e',\n '5ff0f01b-784a-4ddb-85e8-72187ee59758',\n '2287c207-2735-4fca-a24d-5e38bcc01d7d',\n '1349a4b0-a881-4257-9e5c-95fedb91c611',\n '1c58c12e-5a4b-4d9f-b098-a68b68f3aa5a',\n '08e589c3-dac2-434a-bfd3-d65cb647ba19',\n '203b199d-1b0e-4669-8975-7292c13e65b2',\n '1edffff2-b95e-404d-8a58-3acd12a327d5',\n 'a3acbf91-86bd-4f95-8b97-c5fb53430da6',\n 'b4d20aec-f3e2-406f-9cc9-d91812acd674',\n 'd65b8e25-d8eb-4717-80d4-4036415191e0',\n '722d05d5-9aaf-4e0a-b934-546bf9d5e22b',\n 'd7e1cfc4-4472-4987-8653-7ad0cec17401',\n '405146a3-9b6a-478a-b08b-ec226f70ae04',\n '97569ac9-4c3d-4589-a567-c5338ec04ed1',\n '1c51d695-1ee2-4628-95b8-5ab4e153e8b0',\n '5baa3948-e2ea-4dd6-9d1d-50bd974fb70d',\n '442aa751-f9ce-4e5c-b16a-51a726caae7d',\n 'c2b1be74-d7ba-4fc8-91d7-b303e4702350',\n '80156122-6ba1-47c5-a8f6-f1907abcc9b8',\n 'e9043dd7-95c2-46e8-a8e7-49841616177c',\n 'f5aa1962-29cb-4fe1-a155-36bdc903152f',\n 'ab4e0e25-4355-4e46-8030-4415daa908a0',\n '34d2f4b1-6226-4be1-aeb8-3e5641566694',\n '5c9a829b-8eb3-4441-8541-11e7e4b9eb73',\n '984d4821-f8e2-473e-a90b-035d7e4629cb',\n '0e659a1b-77fc-4eb7-bb9b-3d5cfebd9c73',\n 'fc4258e5-1040-4395-a77c-ee8f19c01640',\n '2162a8d6-d9d6-454f-ad54-971b126b2fb8',\n '6d51f610-c692-4363-a304-c11cb8a7d38e',\n '8c57bc98-fa68-490a-88a7-317dda52deff']"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the retrieval chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:04:40.282636627Z",
     "start_time": "2024-09-14T08:04:40.271529632Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Set up system prompt\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "    \n",
    "])\n",
    "\n",
    "# Create the question-answer chain\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the rag bot with a question based on the CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:04:41.600083591Z",
     "start_time": "2024-09-14T08:04:41.453410111Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "\n",
      "Index: 1\n",
      "Customer Id: DD37Cf93aecA6Dc\n",
      "First Name: Sheryl\n",
      "Last Name: Baxter\n",
      "Company: Rasmussen Group\n",
      "City: East Leonard\n",
      "Country: Chile\n",
      "Phone 1: 229.077.5154\n",
      "Phone 2: 397.884.0519x718\n",
      "Email: zunigavanessa@smith.info\n",
      "Subscription Date: 2020-08-24\n",
      "Website: http://www.stephenson.com/\n",
      "\n",
      "Index: 9\n",
      "Customer Id: C2dE4dEEc489ae0\n",
      "First Name: Sheryl\n",
      "Last Name: Meyers\n",
      "Company: Browning-Simon\n",
      "City: Robersonstad\n",
      "Country: Cyprus\n",
      "Phone 1: 854-138-4911x5772\n",
      "Phone 2: +1-448-910-2276x729\n",
      "Email: mariokhan@ryan-pope.org\n",
      "Subscription Date: 2020-01-13\n",
      "Website: https://www.bullock.net/\n",
      "\n",
      "Index: 11\n",
      "Customer Id: 216E205d6eBb815\n",
      "First Name: Carl\n",
      "Last Name: Schroeder\n",
      "Company: Oconnell, Meza and Everett\n",
      "City: Shannonville\n",
      "Country: Guernsey\n",
      "Phone 1: 637-854-0256x825\n",
      "Phone 2: 114.336.0784x788\n",
      "Email: kirksalas@webb.com\n",
      "Subscription Date: 2021-10-20\n",
      "Website: https://simmons-hurley.com/\n",
      "\n",
      "Index: 59\n",
      "Customer Id: 8c7DdF10798bCC3\n",
      "First Name: Kathy\n",
      "Last Name: Hill\n",
      "Company: Moore, Mccoy and Glass\n",
      "City: Selenabury\n",
      "Country: South Georgia and the South Sandwich Islands\n",
      "Phone 1: 001-171-716-2175x310\n",
      "Phone 2: 888.625.0654\n",
      "Email: ncamacho@boone-simmons.org\n",
      "Subscription Date: 2020-11-15\n",
      "Website: http://hayden.com/\n",
      "Human: which company does sheryl Baxter work for?\n"
     ]
    }
   ],
   "source": [
    "answer= rag_chain.invoke({\"input\": \"which company does sheryl Baxter work for?\"})\n",
    "print(answer['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
