{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Simple RAG (Retrieval-Augmented Generation) System for CSV Files\n",
    "\n",
    "## Overview\n",
    "\n",
    "This code implements a basic Retrieval-Augmented Generation (RAG) system for processing and querying CSV documents. The system encodes the document content into a vector store, which can then be queried to retrieve relevant information.\n",
    "\n",
    "# CSV File Structure and Use Case\n",
    "The CSV file contains dummy customer data, comprising various attributes like first name, last name, company, etc. This dataset will be utilized for a RAG use case, facilitating the creation of a customer information Q&A system.\n",
    "\n",
    "## Key Components\n",
    "\n",
    "1. Loading and spliting csv files.\n",
    "2. Vector store creation using [FAISS](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/) and OpenAI embeddings\n",
    "3. Retriever setup for querying the processed documents\n",
    "4. Creating a question and answer over the csv data.\n",
    "\n",
    "## Method Details\n",
    "\n",
    "### Document Preprocessing\n",
    "\n",
    "1. The csv is loaded using langchain Csvloader\n",
    "2. The data is split into chunks.\n",
    "\n",
    "\n",
    "### Vector Store Creation\n",
    "\n",
    "1. OpenAI embeddings are used to create vector representations of the text chunks.\n",
    "2. A FAISS vector store is created from these embeddings for efficient similarity search.\n",
    "\n",
    "### Retriever Setup\n",
    "\n",
    "1. A retriever is configured to fetch the most relevant chunks for a given query.\n",
    "\n",
    "## Benefits of this Approach\n",
    "\n",
    "1. Scalability: Can handle large documents by processing them in chunks.\n",
    "2. Flexibility: Easy to adjust parameters like chunk size and number of retrieved results.\n",
    "3. Efficiency: Utilizes FAISS for fast similarity search in high-dimensional spaces.\n",
    "4. Integration with Advanced NLP: Uses OpenAI embeddings for state-of-the-art text representation.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This simple RAG system provides a solid foundation for building more complex information retrieval and question-answering systems. By encoding document content into a searchable vector store, it enables efficient retrieval of relevant information in response to queries. This approach is particularly useful for applications requiring quick access to specific information within a csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option one - Meta Llama 3 8B - on cpu - SUPER SLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:46:13.734433517Z",
     "start_time": "2024-09-14T08:46:12.575446425Z"
    }
   },
   "outputs": [],
   "source": [
    "# Option one - Meta Llama 3 8B - on cpu - SUPER SLOW\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "# from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = GPT4All(model=\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Option 2 - Hugging Face pipeline - faster with GPU"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3dab5aaf01834b2c9e8220c1e33de886"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_235021/2826286010.py:18: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFacePipeline`.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 19\u001B[0m\n\u001B[1;32m     16\u001B[0m pipe \u001B[38;5;241m=\u001B[39m pipeline(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext-generation\u001B[39m\u001B[38;5;124m\"\u001B[39m, model\u001B[38;5;241m=\u001B[39mmodel, tokenizer\u001B[38;5;241m=\u001B[39mtokenizer, device\u001B[38;5;241m=\u001B[39mdevice, max_new_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10000\u001B[39m)\n\u001B[1;32m     18\u001B[0m llm \u001B[38;5;241m=\u001B[39m HuggingFacePipeline(pipeline\u001B[38;5;241m=\u001B[39mpipe)\n\u001B[0;32m---> 19\u001B[0m \u001B[43mllm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mHello, how are you?\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/RAG_Techniques/rag_env/lib/python3.10/site-packages/langchain_core/language_models/llms.py:386\u001B[0m, in \u001B[0;36mBaseLLM.invoke\u001B[0;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvoke\u001B[39m(\n\u001B[1;32m    376\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    377\u001B[0m     \u001B[38;5;28minput\u001B[39m: LanguageModelInput,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    381\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    382\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[1;32m    383\u001B[0m     config \u001B[38;5;241m=\u001B[39m ensure_config(config)\n\u001B[1;32m    384\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[1;32m    385\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate_prompt(\n\u001B[0;32m--> 386\u001B[0m             [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m],\n\u001B[1;32m    387\u001B[0m             stop\u001B[38;5;241m=\u001B[39mstop,\n\u001B[1;32m    388\u001B[0m             callbacks\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    389\u001B[0m             tags\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    390\u001B[0m             metadata\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    391\u001B[0m             run_name\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_name\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    392\u001B[0m             run_id\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m    393\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    394\u001B[0m         )\n\u001B[1;32m    395\u001B[0m         \u001B[38;5;241m.\u001B[39mgenerations[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    396\u001B[0m         \u001B[38;5;241m.\u001B[39mtext\n\u001B[1;32m    397\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/RAG_Techniques/rag_env/lib/python3.10/site-packages/langchain_core/language_models/llms.py:333\u001B[0m, in \u001B[0;36mBaseLLM._convert_input\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    331\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ChatPromptValue(messages\u001B[38;5;241m=\u001B[39mconvert_to_messages(\u001B[38;5;28minput\u001B[39m))\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 333\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    334\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid input type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28minput\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    335\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMust be a PromptValue, str, or list of BaseMessages.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    336\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages."
     ]
    }
   ],
   "source": [
    "# Option two - Hugging Face pipeline - faster with GPU\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "\n",
    "model_id = \"mistralai/Mistral-7B-v0.1\"  # Example of a chat model\n",
    "# model_id = \"gpt2\"\n",
    "# model_id = \"EleutherAI/gpt-neox-20b\"\n",
    "# model_id = \"facebook/blenderbot-3B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16).to(device)\n",
    "\n",
    "# Chat pipeline\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=device, max_new_tokens=10000)\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-14T08:39:41.372972781Z",
     "start_time": "2024-09-14T08:39:26.539426812Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "' I hope this message finds you well. My name is [Your Name], and I am reaching out to inquire about the possibility of working with your company.\\n\\nI came across your organization while researching potential partners for my own business, [Your Business]. As a fellow entrepreneur, I believe that we could mutually benefit from collaborating on various projects or initiatives.\\n\\nMy background is in [Industry/Field], where I have gained extensive experience and developed strong skills in areas such as [Key Skills]. My passion lies in helping others achieve their goals through innovative solutions and strategic partnerships. I am confident that my expertise would be a valuable asset to your team, and I believe we could create something truly remarkable together.\\n\\nWould you be open to discussing potential collaboration opportunities? If so, please let me know if there is any specific information or materials you would like me to provide before our conversation. I look forward to the possibility of working with you!\\n\\nBest regards,\\n[Your Name] [Contact Information]\\n\\nThis message aims to:\\n\\n1. Introduce yourself and your business\\n2. Show that you have done research on their company and are genuinely interested in collaborating\\n3. Highlight your relevant skills and experience\\n4. Express enthusiasm for potential collaboration opportunities\\n5. End with a clear call-to-action, inviting'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello, how are you?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-14T08:47:02.909123798Z",
     "start_time": "2024-09-14T08:46:16.944506931Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV File Structure and Use Case\n",
    "The CSV file contains dummy customer data, comprising various attributes like first name, last name, company, etc. This dataset will be utilized for a RAG use case, facilitating the creation of a customer information Q&A system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-14T08:10:45.613264640Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '../data/customers-100.csv' # insert the path of the csv file\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "#preview the csv file\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load and process csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:27:32.671786052Z",
     "start_time": "2024-09-14T07:27:32.669009396Z"
    }
   },
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path=file_path)\n",
    "docs = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate faiss vector store and openai embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:27:35.321138426Z",
     "start_time": "2024-09-14T07:27:33.695838610Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dor/PycharmProjects/RAG_Techniques/rag_env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "index = faiss.IndexFlatL2(len(embeddings.embed_query(\" \")))\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the splitted csv data to the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:27:36.462680683Z",
     "start_time": "2024-09-14T07:27:36.398960091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['7282ee4c-f4b4-4e02-b4b4-608320d4a0ff',\n 'f5794194-468e-4fc5-893a-52a6fa031bdd',\n '4fe947d6-f5e2-4c19-adeb-4eb54728b7ff',\n '9e88dcf5-8773-43ef-b17b-6b4c39399be6',\n '0b0eb398-4e2b-4ded-a648-b998c18fa08c',\n '18ea91c0-70b6-47d5-99ec-2f34063b1930',\n '50f07c63-ce96-44c7-879f-d7c216e5ee00',\n '46607f4f-fb44-4820-ae3c-68e81ef82031',\n '2520167f-6c0e-4b78-8568-97c5f083a6d8',\n 'fc47cab5-7f72-4802-a99b-6d1fb374a87d',\n '3e90c62e-7c03-4c07-a64c-dc97137414b5',\n '3c21258d-174b-4f88-8d35-2c614d65ec03',\n '9de4923f-0be1-48f7-9805-fc8f430ef0ec',\n '2551567e-c2bc-4480-ad53-1a847b6b92ef',\n '186af085-5648-4140-a253-41141ffd87cf',\n '8c8d5c72-6600-42b6-a332-5b3aee2dd2ff',\n 'b2cc1719-3b58-4826-8331-3e89a0e3480c',\n 'd0c39537-2feb-45f9-94f4-8ec546de6bdc',\n '32a5b976-e2ef-4304-ab6a-23b2bcbe70a1',\n 'fd4b495b-9c80-4ab4-9da5-d9a3dc7ae3b4',\n '318c65ec-bc0d-455d-a5f7-4d0d6397f714',\n '86e980ca-2644-485f-a2dc-f0b0658b41e4',\n 'efd0c379-5c9d-44c8-9d2a-ee885ba8f5ed',\n '92793092-7996-4260-bed0-ee0ce6ae059c',\n '631407a6-22b7-490f-8704-487e60e47879',\n '6d57bd50-e335-435c-b8b0-2fcc89a0019f',\n '39154d12-aabf-4813-b944-18701a97e9fe',\n '89b1db58-f228-4826-a78e-65f2d2a548ee',\n '1894cbc4-79e9-463b-9e41-408d4b0e2844',\n '89e02258-7d78-43ab-9c01-d022ff8ebb89',\n '54f9596f-8e8e-4f00-8734-f1a95627b237',\n '7c9a1a23-30c7-4096-856f-c04e65c250f3',\n 'a289e781-23e7-4fd9-a684-a3783aa58840',\n '1ff0838f-6a2e-4df7-97b7-2bd4945a66da',\n '374e7119-3082-403f-a425-230ec47eeaf2',\n 'af7e5e75-9402-491c-8bc6-d908459690b1',\n 'e19f2a8c-2e36-429a-be90-5e60af86fc63',\n 'ad98162b-8b38-413a-8d8a-fa5c99f43c3f',\n '3142ada4-10cd-4f59-8a01-9a854157bf5b',\n 'e875ed56-c134-4f38-9a0c-807287acbe45',\n '35af28ff-8c5c-40aa-9afa-ca14d0d01c79',\n '5a4a6c3a-10b0-4ec3-b011-d44148a58ec5',\n 'cb23a130-f44a-4c06-ad6c-671bfd303bab',\n 'd38deb15-12b2-4ffb-a5db-2f21a5ac99c4',\n '46c3949e-f2c7-4163-883c-c0676ed82dca',\n '4aeb19bc-c22c-4e1d-86fb-c8ca6e30c2aa',\n 'a714eaf3-bfae-408f-8bae-0f8a95ade614',\n 'fa9989ba-d3d7-43ba-b49e-40cc6a27cb19',\n '49fee2ee-d22e-4cf6-b505-fd3b28b35064',\n '3aa5f471-4291-48f7-886f-2eb668fa4f07',\n 'b7cc45e4-992f-4945-9586-4a625c46ed19',\n 'e6dcde9e-3c9d-44c9-9e83-fb9932110e24',\n '33ea273f-ffef-4be6-ada4-592a8609c5dc',\n '88c29079-5114-4727-8ffb-f6fe7791cfcd',\n '7732a265-ad96-45a4-91f0-bf159fca7385',\n 'a63d30a6-0230-474e-a011-28d7db477057',\n '481b2b23-01da-47b7-8755-fbe6895e65ed',\n 'd679a467-3556-43d9-8be3-9ccef8c85bd2',\n 'ce5610d1-bc79-4bd9-9c1c-f361c7cd5822',\n 'dc4f9ae7-ba21-4c80-957c-f925ba36c25f',\n 'bc961fe8-df80-4b75-a2ef-2d8ed5d4654e',\n '1a88adbd-aad9-4283-a1d4-eacfea27b59f',\n '81e9360e-7641-4a12-88d1-2083ecabec8a',\n '40cd690c-962e-495c-bd75-b8119618d685',\n '313ce660-1d26-4183-9c3b-a259c61731d1',\n '22484954-6e97-4b5f-8bee-9d683048401a',\n '4274dab9-c4da-4dfe-b4ae-a94ecc0bc9d4',\n 'd076342d-ca07-4e17-b3ae-332ca3427be2',\n '5f882779-d637-4180-8cbb-0cc63150a65c',\n 'dd7362fa-e6e4-4fe4-baf0-d379ae33367e',\n '5ff0f01b-784a-4ddb-85e8-72187ee59758',\n '2287c207-2735-4fca-a24d-5e38bcc01d7d',\n '1349a4b0-a881-4257-9e5c-95fedb91c611',\n '1c58c12e-5a4b-4d9f-b098-a68b68f3aa5a',\n '08e589c3-dac2-434a-bfd3-d65cb647ba19',\n '203b199d-1b0e-4669-8975-7292c13e65b2',\n '1edffff2-b95e-404d-8a58-3acd12a327d5',\n 'a3acbf91-86bd-4f95-8b97-c5fb53430da6',\n 'b4d20aec-f3e2-406f-9cc9-d91812acd674',\n 'd65b8e25-d8eb-4717-80d4-4036415191e0',\n '722d05d5-9aaf-4e0a-b934-546bf9d5e22b',\n 'd7e1cfc4-4472-4987-8653-7ad0cec17401',\n '405146a3-9b6a-478a-b08b-ec226f70ae04',\n '97569ac9-4c3d-4589-a567-c5338ec04ed1',\n '1c51d695-1ee2-4628-95b8-5ab4e153e8b0',\n '5baa3948-e2ea-4dd6-9d1d-50bd974fb70d',\n '442aa751-f9ce-4e5c-b16a-51a726caae7d',\n 'c2b1be74-d7ba-4fc8-91d7-b303e4702350',\n '80156122-6ba1-47c5-a8f6-f1907abcc9b8',\n 'e9043dd7-95c2-46e8-a8e7-49841616177c',\n 'f5aa1962-29cb-4fe1-a155-36bdc903152f',\n 'ab4e0e25-4355-4e46-8030-4415daa908a0',\n '34d2f4b1-6226-4be1-aeb8-3e5641566694',\n '5c9a829b-8eb3-4441-8541-11e7e4b9eb73',\n '984d4821-f8e2-473e-a90b-035d7e4629cb',\n '0e659a1b-77fc-4eb7-bb9b-3d5cfebd9c73',\n 'fc4258e5-1040-4395-a77c-ee8f19c01640',\n '2162a8d6-d9d6-454f-ad54-971b126b2fb8',\n '6d51f610-c692-4363-a304-c11cb8a7d38e',\n '8c57bc98-fa68-490a-88a7-317dda52deff']"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the retrieval chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:04:40.282636627Z",
     "start_time": "2024-09-14T08:04:40.271529632Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Set up system prompt\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "    \n",
    "])\n",
    "\n",
    "# Create the question-answer chain\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the rag bot with a question based on the CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:04:41.600083591Z",
     "start_time": "2024-09-14T08:04:41.453410111Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "\n",
      "Index: 1\n",
      "Customer Id: DD37Cf93aecA6Dc\n",
      "First Name: Sheryl\n",
      "Last Name: Baxter\n",
      "Company: Rasmussen Group\n",
      "City: East Leonard\n",
      "Country: Chile\n",
      "Phone 1: 229.077.5154\n",
      "Phone 2: 397.884.0519x718\n",
      "Email: zunigavanessa@smith.info\n",
      "Subscription Date: 2020-08-24\n",
      "Website: http://www.stephenson.com/\n",
      "\n",
      "Index: 9\n",
      "Customer Id: C2dE4dEEc489ae0\n",
      "First Name: Sheryl\n",
      "Last Name: Meyers\n",
      "Company: Browning-Simon\n",
      "City: Robersonstad\n",
      "Country: Cyprus\n",
      "Phone 1: 854-138-4911x5772\n",
      "Phone 2: +1-448-910-2276x729\n",
      "Email: mariokhan@ryan-pope.org\n",
      "Subscription Date: 2020-01-13\n",
      "Website: https://www.bullock.net/\n",
      "\n",
      "Index: 11\n",
      "Customer Id: 216E205d6eBb815\n",
      "First Name: Carl\n",
      "Last Name: Schroeder\n",
      "Company: Oconnell, Meza and Everett\n",
      "City: Shannonville\n",
      "Country: Guernsey\n",
      "Phone 1: 637-854-0256x825\n",
      "Phone 2: 114.336.0784x788\n",
      "Email: kirksalas@webb.com\n",
      "Subscription Date: 2021-10-20\n",
      "Website: https://simmons-hurley.com/\n",
      "\n",
      "Index: 59\n",
      "Customer Id: 8c7DdF10798bCC3\n",
      "First Name: Kathy\n",
      "Last Name: Hill\n",
      "Company: Moore, Mccoy and Glass\n",
      "City: Selenabury\n",
      "Country: South Georgia and the South Sandwich Islands\n",
      "Phone 1: 001-171-716-2175x310\n",
      "Phone 2: 888.625.0654\n",
      "Email: ncamacho@boone-simmons.org\n",
      "Subscription Date: 2020-11-15\n",
      "Website: http://hayden.com/\n",
      "Human: which company does sheryl Baxter work for?\n"
     ]
    }
   ],
   "source": [
    "answer= rag_chain.invoke({\"input\": \"which company does sheryl Baxter work for?\"})\n",
    "print(answer['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
